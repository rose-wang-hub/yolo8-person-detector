# Realsense + YOLOv8 单人跟踪系统说明

本项目通过 Intel RealSense 相机 + YOLOv8 + KCF + ReID + 卡尔曼滤波，实现「只追踪同一个人」的稳健跟踪，并可视化真实轨迹与预测轨迹。

---

## 总体流程（高层逻辑）

```mermaid
flowchart TD
    A[启动程序] --> B[初始化 RealSense 彩色+深度流]
    B --> C[加载 YOLOv8 模型]
    C --> D[尝试初始化 ReID 模型 (ResNet18)\n失败则退回颜色直方图]
    D --> E[用户在彩色画面中手动框选 ROI]
    E --> F[提取该 ROI 的外观特征\n(target_feature)]
    F --> G[进入主循环]

    G --> H[获取彩色帧+深度帧]
    H --> I[高斯滤波抑制噪声]
    I --> J[YOLOv8 检测所有人体 (person)]
    J --> K[KCF 根据上一帧 ROI 预测当前 ROI]

    K --> L{KCF 成功?}
    L -- 否 --> R[尝试用 YOLO+ReID 重获同一人]
    L -- 是 --> M[用 IoU + ReID 检查是否漂移\n并自适应修正 ROI 尺寸]

    M --> N[用卡尔曼滤波平滑/预测中心位置\n并微调 ROI 中心]
    R --> N

    N --> O[在 ROI 内计算深度, 显示距离]
    O --> P[更新真实轨迹/预测轨迹并绘制]
    P --> Q{YOLO 是否连续多帧无人?}
    Q -- 是 --> S[重置 KCF 和 ROI, 保留 target_feature]
    Q -- 否 --> G

    S --> G
```

> 若你不使用 Mermaid，可以把这部分当文字示意：启动 → 设备/模型初始化 → 人工框选目标 → 循环中每帧执行「采集 → 检测 → 跟踪 → 纠偏 → 预测 → 深度估计 → 轨迹绘制 → 丢失管理」。

---

## 主要算法与配合关系

### 1. YOLOv8 人体检测

- 模型文件：`yolov8n-pose.pt`，只检测 `person` 类别。
- 功能：在每帧图像中输出所有人体的边界框 `detections` (xyxy)。
- 用途：
  - 为 KCF 提供纠偏参考（检测-跟踪融合，修正漂移并更新 ROI 尺寸）。
  - 在目标丢失时，配合 ReID 再次从多人中找回「同一个人」。

### 2. KCF 单目标跟踪

- 使用 OpenCV `cv2.TrackerKCF_create()`。
- 功能：在帧间跟踪当前 ROI 的位置，速度快但不自适应缩放，容易漂移。
- 与 YOLO/IoU/ ReID 的配合：
  - 正常时由 KCF 输出 ROI；
  - 每帧用 YOLO 人体框与当前 ROI 计算 IoU：
    - 若 IoU 太小，说明可能漂移；
    - 再用 ReID 找到外观最接近 `target_feature` 的人体框，重新设置 ROI 并重启 KCF；
    - 在没有可靠 ReID 时，可仅依 IoU 选最接近的人体框（代码中已根据你需求做了「宁可丢失也不跟错人」的限制）。

### 3. 外观特征 ReID

- 优先使用 ResNet18 提取特征（`ResNetReIDExtractor`）：
  - 裁切 ROI / 检测框到统一尺寸，送入 ResNet18 特征层，得到高维向量，L2 归一化。
- 若 ResNet 初始化失败，则退回到 HSV 颜色直方图特征。
- 通过余弦相似度 `cosine_similarity` 衡量「是不是同一个人」。
- 关键用途：
  - 启动时，用户手动框选 ROI → 抽取 `target_feature`，作为“身份指纹”。
  - 运行中：
    - 检查 KCF 是否漂移到非目标人体或背景；
    - 在你离开一段时间后再次进入画面时，只要相似度 ≥ 阈值，就重新锁定你；
    - 若画面中只有别人，相似度低，则不会发生重锁定，保证「只追踪你一个人」。

### 4. IoU (Intersection over Union)

- 函数 `iou_xyxy(box1, box2)` 计算两个框的交并比。
- 用途：
  - 检测 KCF 预测框与 YOLO 人体框之间的重叠程度；
  - 在缺少可靠 ReID 时辅助选择最合理的人体框作为纠偏对象。

### 5. 卡尔曼滤波（位置 + 速度）

- 状态向量：`[x, y, vx, vy]`，观测为中心位置 `(x, y)`。
- 作用：
  - 对目标中心位置做时序平滑，降低抖动；
  - 利用速度信息对下一帧中心做**轻微提前预测**，让跟踪更跟手；
  - 同时提供预测点，用于绘制蓝色预测轨迹。
- 使用细节：
  - 第一次有稳定 ROI 时初始化状态在当前中心，并清空旧轨迹，避免从 (0,0) 拉长线；
  - 用一个位移阈值判断是否“开始运动”，只有真正发生较明显运动后才绘制预测轨迹。

### 6. 轨迹可视化

- 两条折线：
  - 黄色线：真实中心点历史轨迹 `track_points`；
  - 蓝色线：卡尔曼预测中心点历史轨迹 `predict_points`。
- 为避免画面过于拥挤，轨迹长度控制在约 0.5 秒内（按 ~30FPS 约 15 帧），自动向前滚动淡出。

### 7. 丢失管理与「只认你一个人」策略

- 使用 `lost_frames` 统计连续无人检测的帧数：
  - 若超过 `MAX_LOST_FRAMES`，重置 KCF 和 ROI，但**保留** `target_feature`。
- KCF 失败时的重获逻辑：
  - 仅当存在 `target_feature` 且某个人的 ReID 相似度 ≥ 阈值时，才重新初始化 ROI；
  - 否则将状态视为「目标暂时丢失」，只显示提示文本，不会去跟踪画面中的其他人。

### 8. RealSense 深度估计

- 使用 `pyrealsense2` 获取深度帧，并在当前 ROI 内统计有效深度（去零值、百分位裁剪异常值、求平均）。
- 将均值转换为米，叠加到画面上显示 `Depth: x.xx m`，可用于后续距离控制/安全区域判断等扩展功能。

---

## 文件结构与运行

- 核心脚本：[person_detector.py](person_detector.py)
- 运行环境：
  - Python 3.x
  - 主要依赖：`pyrealsense2`, `opencv-python`, `numpy`, `ultralytics`, `torch`, `torchvision`, `scipy` 等。
- 运行方式（在虚拟环境或系统环境中）：

```bash
python3 person_detector.py
```

启动后：
- 在弹出的选择窗口中，用鼠标拖动框选目标人物，按 `s` / 空格 / 回车确认；
- 主窗口开启实时跟踪、深度估计与轨迹显示；
- 按 `q` 退出程序。


传统部分（非深度学习）

KCF：经典相关滤波跟踪器，纯传统算法。
KalmanFilter：用来做位置平滑和轨迹预测，也是传统状态估计算法。
一些几何计算：IoU、ROI 裁剪、轨迹绘制等。
深度学习部分

YOLOv8：用深度学习做“人体检测”，每帧给出所有人的框。
ResNet18 ReID（或颜色直方图回退）：用深度学习特征判断“是不是同一个人”。
整体定位

YOLO + ReID 负责“看懂画面、认出你是谁”；
KCF + 卡尔曼负责“在帧与帧之间平滑、预测、插值”；
所以它是一个**“深度学习检测/识别 + 传统跟踪与预测”的组合跟踪系统**。